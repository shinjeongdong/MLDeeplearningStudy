{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "17TU7yXOFDL2YIlnFosF6TWb9B7TI5rV8",
      "authorship_tag": "ABX9TyM/awr6zktsC8K8XFIAMZih",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shinjeongdong/MLDeeplearningStudy/blob/main/%5BPyTorch%5D/%5BPyTorch%5D_5_2_%EB%82%98%EB%A7%8C%EC%9D%98_%EB%AA%A8%EB%93%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#import"
      ],
      "metadata": {
        "id": "m2sFEhqRmTH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#주요 함수를 모듈화 해서 가독성과 코드를 줄임\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/func/')\n",
        "from multiclass_functions1 import *\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFSt3y-ilgMt",
        "outputId": "94c0582f-59a9-49aa-bf6d-ae78cab75b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "LR = 1e-3\n",
        "EPOCH = 5\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "new_model_train = False\n",
        "model_type = 'MLP'\n",
        "dataset = \"MNSIT\"\n",
        "save_model_path = f\"/content/drive/MyDrive/Colab Notebooks/results/{model_type}.pt\""
      ],
      "metadata": {
        "id": "1Bo18od_n_gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()\n",
        "train_DS = datasets.MNIST(root = \"/content/drive/MyDrive/Colab Notebooks\", train=True, download= True, transform=transform)\n",
        "test_DS = datasets.MNIST(root = \"/content/drive/MyDrive/Colab Notebooks\", train=False, download= True, transform=transform)\n",
        "train_DL = torch.utils.data.DataLoader(train_DS, batch_size = BATCH_SIZE, shuffle = True) # 32개 무작위\n",
        "test_DL = torch.utils.data.DataLoader(test_DS, batch_size = BATCH_SIZE, shuffle = True) # 32개 무작위"
      ],
      "metadata": {
        "id": "BIFrTbSYphYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fcs = nn.Sequential(nn.Linear(28*28, 100),\n",
        "                             nn.ReLU(),\n",
        "                             nn.Linear(100,10)) #짜피 로스를 ce로 잡으면 자동으로 소프트맥스가 됨\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = torch.flatten(x,start_dim = 1)\n",
        "    x = self.fcs(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "G-nMKUdppo4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = globals()[model_type]().to(DEVICE)\n",
        "print(model)\n",
        "x_batch,_ = next(iter(train_DL))\n",
        "print(x_batch.shape)\n",
        "print(model(x_batch.to(DEVICE)).shape) #로짓"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oECc290ntaLb",
        "outputId": "e5f7f3ed-143c-4e46-d554-89246c202b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (fcs): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=100, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "torch.Size([32, 1, 28, 28])\n",
            "torch.Size([32, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if new_model_train:\n",
        "  optimizer = optim.Adam(model.parameters(), lr = LR)\n",
        "  loss_history = Train(model, train_DL, criterion, optimizer, EPOCH)\n",
        "\n",
        "  torch.save(model,save_model_path)\n",
        "\n",
        "  plt.plot(range(1,EPOCH + 1),loss_history)\n",
        "  plt.xlabel(\"EPOCH\")\n",
        "  plt.ylabel(\"loss\")\n",
        "  plt.title(\"Train loss\")\n",
        "  plt.grid()"
      ],
      "metadata": {
        "id": "NmdQmOkztseK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_model = torch.load(save_model_path,map_location=DEVICE, weights_only= False)"
      ],
      "metadata": {
        "id": "QHUzJl1YuD9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test(load_model,test_DL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeCctivZvJhE",
        "outputId": "c4f763d6-8dc8-4857-b82a-be70f6810b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 9747/10000 (97.5 %)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모듈 함수"
      ],
      "metadata": {
        "id": "MaGbnJHvpu1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def Train(model,train_DL,criterion, optimizer, EPOCH):\n",
        "\n",
        "  loss_history = [] #로스 저장용 리스트\n",
        "  Not = len(train_DL.dataset) #60000\n",
        "\n",
        "  model.train() #학습모드\n",
        "  for ep in range(EPOCH):\n",
        "    rloss = 0 #running loss\n",
        "    for x_batch, y_batch in train_DL: #60000개를 32,1,28,28로 꺼내서 학습함 미니배치 학습\n",
        "      x_batch = x_batch.to(DEVICE) # 32,1,28,28\n",
        "      y_batch = y_batch.to(DEVICE)\n",
        "      #inference 추론\n",
        "      y_hat = model(x_batch) #x_batch 32개를 넣고 y_hat값을 얻음\n",
        "      #loss\n",
        "      loss = criterion(y_hat,y_batch) #그 y_hat이랑 y정답값을 이용해 로스 손실 얻음\n",
        "\n",
        "      #update\n",
        "      optimizer.zero_grad() #gd 누적 막기위한 초기화\n",
        "      loss.backward() #역전파 : W에 대한 편미분\n",
        "      optimizer.step() #업데이트\n",
        "      #loss accumulation\n",
        "      loss_b = loss.item() * x_batch.shape[0] #로스랑 32를곱함 왜? CE는 자동으로 평균값을 나타냄 고로 다시 32를 곱해서 전체합을 나타냄\n",
        "      rloss += loss_b #그것을 rloss에다 누적함 다 누적하면 60000개 대한 로스가 더해짐\n",
        "    #print loss\n",
        "    loss_e = rloss/Not # 그걸 60000개로 나눠준다 그러면 전체 EPOCH에 대한 로스 평균이 구해짐\n",
        "    loss_history += [loss_e]\n",
        "    print(f\"Epoch : {ep + 1}, train_loss : {loss_e:.3f}\")\n",
        "    print(\"-\"*20)\n",
        "  return loss_history\n",
        "\n",
        "\n",
        "def Test(model, test_DL):\n",
        "\n",
        "  model.eval() #eval no_grad는 외우자\n",
        "  with torch.no_grad():\n",
        "    rcorrect = 0 #맞춘개수 누적\n",
        "    for x_batch,y_batch in test_DL:\n",
        "      x_batch = x_batch.to(DEVICE) #32,1,28,28\n",
        "      y_batch = y_batch.to(DEVICE) #(32)\n",
        "      #inference\n",
        "      y_hat = model(x_batch) #y_hat 구하고 (32,10)\n",
        "      #corrects accumulation\n",
        "      pred = y_hat.argmax(dim = 1) #32행에서 가로축 원소들 중에 가장 큰값들의 인덱스만 꺼내옴 (32) #1차원\n",
        "      corrects_b = torch.sum(pred == y_batch).item() # 예측값이랑 정답값이랑 일치하는지\n",
        "      #print(pred)\n",
        "\n",
        "      rcorrect += corrects_b #누적시킴\n",
        "\n",
        "    accuracy_e = rcorrect / len(test_DL.dataset) * 100 # 그러면 (정답수 / 전체 데이터 수)해서 정답률 가능\n",
        "\n",
        "  print(f\"Test accuracy: {rcorrect}/{len(test_DL.dataset)} ({accuracy_e:.1f} %)\")\n",
        "\n",
        "\n",
        "def Test_plot(model,test_DL):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    x_batch, y_batch = next(iter(test_DL))\n",
        "    x_batch = x_batch.to(DEVICE)\n",
        "    y_hat = model(x_batch)\n",
        "    pred = y_hat.argmax(dim = 1)\n",
        "\n",
        "  x_batch = x_batch.to('cpu')\n",
        "\n",
        "\n",
        "  plt.figure(figsize = (8,4))\n",
        "  for idx in range(6):\n",
        "    plt.subplot(2,3, idx+1,xticks = [], yticks=[])\n",
        "    plt.imshow(x_batch[idx].permute(1,2,0).squeeze(), cmap='gray')\n",
        "    pred_class = test_DL.dataset.classes[pred[idx]]\n",
        "    true_class = test_DL.dataset.classes[y_batch[idx]]\n",
        "    plt.title(f\"{pred_class} ({true_class})\",color = 'g' if pred_class == true_class else \"r\")\n",
        "\n",
        "\n",
        "def count_params(model):\n",
        "  num = sum([p.numel() for p in model.parameters() if p.requires_grad]) #numel = 행렬의 원소의 개수 리턴\n",
        "  return num\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z99UxUJMp0Ra"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}